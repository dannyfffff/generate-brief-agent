# import streamlit as st
# import os
# from dotenv import load_dotenv
# from graph import graph  # å¯¼å…¥æ‚¨ç¼–è¯‘å¥½çš„ LangGraph
# from typing import Literal, Optional
# import logging
# import sys
#
# # --- 1. é…ç½®å’Œåˆå§‹åŒ– ---
#
# # ç¡®ä¿åœ¨ Streamlit åº”ç”¨å¯åŠ¨æ—¶åŠ è½½ç¯å¢ƒå˜é‡
# # æ³¨æ„ï¼šStreamlit è¿è¡Œæ—¶å¯èƒ½éœ€è¦é‡æ–°è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œè¯·ç¡®ä¿æ‚¨çš„ .env æ–‡ä»¶åœ¨è·¯å¾„ä¸­ã€‚
# load_dotenv()
#
# # æ£€æŸ¥å…³é”®ç¯å¢ƒå˜é‡ï¼ˆå¯é€‰ï¼Œä½†æ¨èï¼‰
# if not os.getenv("TAVILY_API_KEY") or not os.getenv("DEEPSEEK_API_KEY"):
#     st.error("ğŸš¨ é”™è¯¯ï¼šTAVILY_API_KEY æˆ– DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®ã€‚è¯·æ£€æŸ¥æ‚¨çš„ .env æ–‡ä»¶ã€‚")
#     st.stop()
#
# # è®¾ç½®æ—¥å¿—çº§åˆ«ä¸º DEBUGï¼Œè¿™æ · graph.invoke å°±ä¼šæ‰“å°å‡ºæ¯ä¸€æ­¥çš„è¾“å…¥ã€è¾“å‡ºå’ŒçŠ¶æ€æ›´æ–°ã€‚
# logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)
# logging.getLogger().handlers = []
# logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))
#
#
# # --- 2. æ ¸å¿ƒçŠ¶æ€å®šä¹‰ ---
#
# # æ¨¡æ‹Ÿç”¨æˆ·åœ¨ user_query_node èŠ‚ç‚¹ä¸­çš„é€‰æ‹©
# @st.cache_data
# def get_initial_state():
#     """è·å– LangGraph åˆå§‹çŠ¶æ€ç»“æ„"""
#     return {
#         "workflowInput": "",
#         "optionId": None,
#         "optionContent": None,
#         "it_doc_results": None,
#         # ... æ‚¨çš„æ‰€æœ‰å…¶ä»–çŠ¶æ€é”®å¯ä»¥çœç•¥ï¼ŒGraph ä¼šè‡ªåŠ¨åˆå§‹åŒ–ç¼ºå¤±çš„é”®
#     }
#
#
# # --- 3. è¾…åŠ©å‡½æ•°ï¼šè¿è¡Œ LangGraph ---
#
# # ä¸ºäº†åœ¨ Streamlit é‡æ–°è¿è¡Œæ—¶é¿å…é‡å¤ç¼–è¯‘å’Œè¿è¡Œï¼Œä½¿ç”¨ç¼“å­˜
# def run_langgraph(user_input: str, option_id: Literal["A", "B", "C"]):
#     """æ‰§è¡Œ LangGraph æµç¨‹å¹¶è¿”å›æœ€ç»ˆçŠ¶æ€"""
#
#     # æ¨¡æ‹Ÿ user_query_node çš„è¡Œä¸ºï¼š
#     # 1. åœ¨æµç¨‹å¼€å§‹æ—¶ï¼Œæˆ‘ä»¬è®¾ç½®åˆå§‹çš„ç”¨æˆ·è¾“å…¥ã€‚
#     # 2. å‡è®¾ user_query_node èŠ‚ç‚¹åªæ˜¯ä¸€ä¸ªæç¤ºç‚¹ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œæå‰è®¾ç½®ç”¨æˆ·é€‰æ‹©
#     #    (ä¸ºäº†ç®€åŒ– Streamlit éƒ¨ç½²ï¼Œæˆ‘ä»¬æš‚æ—¶è·³è¿‡ç”¨æˆ·äºŒæ¬¡ç¡®è®¤ç¯èŠ‚ï¼Œå¼ºåˆ¶é€‰æ‹© A ä¸”æ— å¤§çº²)
#
#     initial_state = {
#         "workflowInput": user_input,
#         "optionId": option_id,
#         # å¼ºåˆ¶è®¾ç½® user_query_node åç»­è·¯ç”±æ‰€éœ€çš„å€¼
#         "userChoiceId": "A",
#         "userOutline": "",
#     }
#
#     config = {"recursion_limit": 100}  # è®¾ç½®æœ€å¤§é€’å½’é™åˆ¶
#
#     st.info(f"ğŸš€ å¼€å§‹æ‰§è¡Œ LangGraph æµç¨‹ï¼šè¾“å…¥='{user_input}'ï¼Œç±»å‹='{option_id}'...")
#
#     try:
#         # å®æ—¶æ‰“å°æ‰§è¡Œæ­¥éª¤ (éœ€è¦å®šåˆ¶ LangGraph çš„é…ç½®æˆ–ä½¿ç”¨å›è°ƒ)
#         # è¿™é‡Œæˆ‘ä»¬åªè¿è¡Œåˆ°ç»“æŸ
#         final_state = graph.invoke(initial_state, config=config)
#
#         st.success("âœ… LangGraph æµç¨‹æ‰§è¡Œå®Œæ¯•ï¼")
#         return final_state
#
#     except Exception as e:
#         st.error(f"âŒ LangGraph æ‰§è¡Œå¤±è´¥: {e}")
#         st.code(final_state.get('error', 'æœªæ•è·çš„é”™è¯¯ä¿¡æ¯'))
#         return None
#
#
# # --- 4. Streamlit ç•Œé¢ ---
#
# st.set_page_config(page_title="LangGraph ç®€æŠ¥ç”Ÿæˆåº”ç”¨", layout="wide")
#
# st.title("ğŸ“ è‡ªåŠ¨åŒ–ç®€æŠ¥ç”Ÿæˆç³»ç»Ÿ")
# st.markdown("åŸºäº LangGraph çš„å¤šæºä¿¡æ¯æ£€ç´¢ã€åˆ†æä¸æ–‡æ¡£å¯¼å‡ºå·¥ä½œæµã€‚")
#
# # --- è¾“å…¥è¡¨å• ---
# with st.form("briefing_form"):
#     # 1. ç”¨æˆ·è¾“å…¥æŸ¥è¯¢
#     workflow_input = st.text_input(
#         "è¯·è¾“å…¥è¦åˆ†æçš„ä¸»é¢˜æˆ–äº‹ä»¶:",
#         placeholder="ä¾‹å¦‚ï¼šæ¬§ç›Ÿæœ€æ–° AI ç›‘ç®¡æ”¿ç­–å¯¹æˆ‘å›½äº’è”ç½‘ä¼ä¸šçš„å½±å“",
#         key="workflow_input_key"
#     )
#
#     # 2. é€‰é¡¹é€‰æ‹© (å¯¹åº” optionId)
#     option_map = {
#         "A": "A - æ”¿ç­–ç±» (æ”¿ç­–å†…å®¹åˆ†æ)",
#         "B": "B - æŠ€æœ¯ç±» (æŠ€æœ¯æ€è€ƒåˆ†æ)",
#         "C": "C - äº‹ä»¶ç±» (äº‹ä»¶æ·±å±‚åˆ†æ)"
#     }
#     option_id_choice = st.radio(
#         "è¯·é€‰æ‹©ç®€æŠ¥ç±»å‹ (å¯¹åº” optionId):",
#         options=list(option_map.keys()),
#         format_func=lambda x: option_map[x],
#         key="option_id_key",
#         horizontal=True
#     )
#
#     # 3. æäº¤æŒ‰é’®
#     submitted = st.form_submit_button("å¼€å§‹ç”Ÿæˆç®€æŠ¥")
#
# # --- ç»“æœå±•ç¤º ---
# if submitted and workflow_input:
#
#     # è¿è¡Œ LangGraph
#     final_state = run_langgraph(workflow_input, option_id_choice)
#
#     if final_state:
#
#         # æå–å…³é”®ç»“æœ
#         export_path = final_state.get('export_path', 'KEY_MISSING_IN_FINAL_STATE')
#         briefing_draft = final_state.get('briefing_draft')
#         final_briefing = final_state.get('final_briefing')
#
#         with st.expander("æŸ¥çœ‹æ‰€æœ‰çŠ¶æ€å˜é‡ (è°ƒè¯• - å®Œæ•´)", expanded=True):
#             st.json(final_state)  # è§‚å¯Ÿè¿™ä¸ªè¾“å‡º
#
#         st.subheader("ğŸ‰ æœ€ç»ˆç»“æœ")
#
#         if export_path != 'KEY_MISSING_IN_FINAL_STATE' and "å¯¼å‡ºå¤±è´¥" not in export_path:
#             st.success(f"æ–‡ä»¶å·²ä¿å­˜è‡³ï¼š`{export_path}`")
#             # å°è¯•æä¾›ä¸‹è½½æŒ‰é’®ï¼ˆå‡è®¾æ–‡ä»¶ä½äº Streamlit åº”ç”¨å¯è®¿é—®çš„è·¯å¾„ï¼‰
#             try:
#                 with open(export_path, "rb") as file:
#                     st.download_button(
#                         label="ä¸‹è½½ DOCX ç®€æŠ¥",
#                         data=file,
#                         file_name=os.path.basename(export_path),
#                         mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
#                     )
#             except Exception as e:
#                 st.warning(f"æ— æ³•åˆ›å»ºä¸‹è½½é“¾æ¥ï¼Œè¯·æ‰‹åŠ¨ä» {export_path} è·å–æ–‡ä»¶ã€‚é”™è¯¯: {e}")
#         else:
#             st.warning(f"DOCX æ–‡ä»¶å¯¼å‡ºå¤±è´¥æˆ–è·¯å¾„æœªè¿”å›ã€‚è¯Šæ–­å€¼: {export_path}")
#
#         # è¯¦ç»†å†…å®¹é¢„è§ˆ
#         with st.expander("é¢„è§ˆæœ€ç»ˆç®€æŠ¥å†…å®¹ (æ–‡æœ¬)", expanded=False):
#             if final_briefing:
#                 st.code(final_briefing, language='markdown')
#             else:
#                 st.write("æœ€ç»ˆç®€æŠ¥å†…å®¹ä¸ºç©ºã€‚")
#
#         # è°ƒè¯•ä¿¡æ¯
#         with st.expander("æŸ¥çœ‹ç¬¬ä¸€ç« åˆç¨¿ (è°ƒè¯•)", expanded=False):
#             st.markdown(briefing_draft)
#
#         with st.expander("æŸ¥çœ‹æ‰€æœ‰çŠ¶æ€å˜é‡ (è°ƒè¯•)", expanded=False):
#             st.json(final_state)
#
# elif submitted and not workflow_input:
#     st.warning("è¯·è¾“å…¥è¦åˆ†æçš„ä¸»é¢˜æˆ–äº‹ä»¶æ‰èƒ½å¼€å§‹ã€‚")

import streamlit as st
import os
import glob  # ã€æ–°å¢ã€‘å¯¼å…¥ glob æ¨¡å—
from dotenv import load_dotenv
from graph import graph
from typing import Literal, Optional
import logging
import sys
from datetime import datetime
# --- 1. é…ç½®å’Œåˆå§‹åŒ– ---

load_dotenv()

if not os.getenv("TAVILY_API_KEY") or not os.getenv("DEEPSEEK_API_KEY"):
    st.error("ğŸš¨ é”™è¯¯ï¼šTAVILY_API_KEY æˆ– DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®ã€‚è¯·æ£€æŸ¥æ‚¨çš„ .env æ–‡ä»¶ã€‚")
    st.stop()

logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)
logging.getLogger().handlers = []
logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))


# --- 2. æ ¸å¿ƒçŠ¶æ€å®šä¹‰ ---

@st.cache_data
def get_initial_state():
    """è·å– LangGraph åˆå§‹çŠ¶æ€ç»“æ„"""
    return {
        "workflowInput": "",
        "optionId": None,
        "it_doc_results": None,
    }


# --- ã€æ–°å¢ã€‘è¾…åŠ©å‡½æ•°ï¼šæŸ¥æ‰¾æœ€æ–°çš„ç®€æŠ¥æ–‡ä»¶ ---
def find_latest_briefing_file(directory="generated_briefings"):
    """
    åœ¨æŒ‡å®šç›®å½•ä¸‹æŸ¥æ‰¾æœ€æ–°çš„ DOCX ç®€æŠ¥æ–‡ä»¶ã€‚
    å®ƒç”¨äºåœ¨ LangGraph è·¯å¾„è¿”å›å¤±è´¥æ—¶ï¼Œä»æœ¬åœ°ç›®å½•ä¸­æ¢å¤æ–‡ä»¶ã€‚
    """
    try:
        if not os.path.isdir(directory):
            return None

        # æŸ¥æ‰¾æ‰€æœ‰ DOCX æ–‡ä»¶
        # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾æ–‡ä»¶åä¸­åŒ…å« 'ç®€æŠ¥' æˆ– 'åˆ†æ' ç­‰å…³é”®è¯ï¼Œå¦‚æœæ‚¨çš„å‘½åè§„åˆ™å›ºå®šï¼Œå¯ä»¥ä¼˜åŒ– glob æ¨¡å¼
        list_of_files = glob.glob(os.path.join(directory, '*.docx'))
        if not list_of_files:
            return None

        # æ’é™¤ä¸´æ—¶æ–‡ä»¶ï¼ˆå¦‚ Word äº§ç”Ÿçš„ ~$ï¼‰ï¼Œå¹¶æŒ‰æ–‡ä»¶åˆ›å»ºæ—¶é—´æ’åº
        valid_files = [f for f in list_of_files if not os.path.basename(f).startswith('~') and os.path.getsize(f) > 0]
        if not valid_files:
            return None

        # æ‰¾åˆ°åˆ›å»ºæ—¶é—´æœ€æ–°çš„æ–‡ä»¶
        latest_file = max(valid_files, key=os.path.getctime)
        return latest_file
    except Exception as e:
        st.error(f"æŸ¥æ‰¾æœ¬åœ°æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return None


# ã€æ–°å¢ã€‘è¾…åŠ©å‡½æ•°ï¼šè·å–æ‰€æœ‰å†å²ç®€æŠ¥
def get_historical_briefings(directory="generated_briefings"):
    """è·å–æ‰€æœ‰å·²ç”Ÿæˆçš„ç®€æŠ¥æ–‡ä»¶ï¼ˆæŒ‰æ—¶é—´é™åºæ’åˆ—ï¼‰ã€‚"""
    if not os.path.isdir(directory):
        return []

    # æŸ¥æ‰¾æ‰€æœ‰ DOCX æ–‡ä»¶
    list_of_files = glob.glob(os.path.join(directory, '*.docx'))

    # æ’é™¤ä¸´æ—¶æ–‡ä»¶ï¼Œå¹¶è·å–æ–‡ä»¶ä¿¡æ¯
    file_details = []
    for f in list_of_files:
        try:
            if not os.path.basename(f).startswith('~') and os.path.getsize(f) > 0:
                file_details.append({
                    'path': f,
                    'name': os.path.basename(f),
                    'time': os.path.getctime(f)
                })
        except OSError:
            # å¿½ç•¥æ— æ³•è®¿é—®çš„æ–‡ä»¶
            continue

    # æŒ‰æ—¶é—´é™åºæ’åˆ— (æœ€æ–°çš„åœ¨å‰)
    file_details.sort(key=lambda x: x['time'], reverse=True)

    return file_details
# --- 3. è¾…åŠ©å‡½æ•°ï¼šè¿è¡Œ LangGraph ---

def run_langgraph(user_input: str, option_id: Literal["A", "B", "C"]):
    """æ‰§è¡Œ LangGraph æµç¨‹å¹¶è¿”å›æœ€ç»ˆçŠ¶æ€"""

    initial_state = {
        "workflowInput": user_input,
        "optionId": option_id,
        "userChoiceId": "A",
        "userOutline": "",
    }

    config = {"recursion_limit": 100}

    st.info(f"ğŸš€ å¼€å§‹æ‰§è¡Œ LangGraph æµç¨‹ï¼šè¾“å…¥='{user_input}'ï¼Œç±»å‹='{option_id}'...")

    try:
        final_state = graph.invoke(initial_state, config=config)
        st.success("âœ… LangGraph æµç¨‹æ‰§è¡Œå®Œæ¯•ï¼")
        return final_state

    except Exception as e:
        # åœ¨æ•è·é”™è¯¯æ—¶ï¼Œä¾ç„¶è¿”å› final_state ä»¥ä¾¿è°ƒè¯•
        final_state = graph.get_state(config).values if graph.get_state(config) else {}
        st.error(f"âŒ LangGraph æ‰§è¡Œå¤±è´¥: {e}")
        st.code(final_state.get('error', 'æœªæ•è·çš„é”™è¯¯ä¿¡æ¯'))
        return final_state


# --- 4. Streamlit ç•Œé¢ ---

st.set_page_config(page_title="LangGraph ç®€æŠ¥ç”Ÿæˆåº”ç”¨", layout="wide")

st.title("ğŸ“ è‡ªåŠ¨åŒ–ç®€æŠ¥ç”Ÿæˆç³»ç»Ÿ")
st.markdown("åŸºäº LangGraph çš„å¤šæºä¿¡æ¯æ£€ç´¢ã€åˆ†æä¸æ–‡æ¡£å¯¼å‡ºå·¥ä½œæµã€‚")

# --- å†å²ç”Ÿæˆæ–‡æ¡£å±•ç¤ºæ¨¡å— ---
st.subheader("ğŸ“ å†å²ç”Ÿæˆæ–‡æ¡£")
historical_files = get_historical_briefings()

if historical_files:
    with st.expander("ç‚¹å‡»æŸ¥çœ‹å’Œä¸‹è½½æ‰€æœ‰å†å²ç®€æŠ¥ (å…± {} ä»½)".format(len(historical_files)), expanded=False):
        for file_info in historical_files:
            file_path = file_info['path']
            file_name = file_info['name']

            # æ ¼å¼åŒ–æ—¶é—´
            time_str = datetime.fromtimestamp(file_info['time']).strftime('%Y-%m-%d %H:%M:%S')

            # ä½¿ç”¨åˆ—å¸ƒå±€
            col1, col2 = st.columns([4, 1])

            with col1:
                st.write(f"**{file_name}**")
                st.caption(f"*ç”Ÿæˆæ—¶é—´: {time_str}*")

            with col2:
                try:
                    # ç¡®ä¿æ–‡ä»¶å­˜åœ¨ä¸”å¯è¯»
                    if os.path.exists(file_path):
                        with open(file_path, "rb") as file:
                            st.download_button(
                                label="ä¸‹è½½",
                                data=file.read(),
                                file_name=file_name,
                                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                                key=f"download_{file_name}"  # å¿…é¡»æœ‰å”¯ä¸€çš„key
                            )
                except Exception:
                    st.caption("æ–‡ä»¶ä¸å¯è¯»")
else:
    st.info("ç›®å‰è¿˜æ²¡æœ‰å†å²ç®€æŠ¥æ–‡ä»¶ã€‚")

st.markdown("---")  # åˆ†éš”çº¿

# --- è¾“å…¥è¡¨å• ---
with st.form("briefing_form"):
    workflow_input = st.text_input(
        "è¯·è¾“å…¥è¦åˆ†æçš„ä¸»é¢˜æˆ–äº‹ä»¶:",
        placeholder="ä¾‹å¦‚ï¼šæ¬§ç›Ÿæœ€æ–° AI ç›‘ç®¡æ”¿ç­–å¯¹æˆ‘å›½äº’è”ç½‘ä¼ä¸šçš„å½±å“",
        key="workflow_input_key"
    )

    option_map = {
        "A": "A - æ”¿ç­–ç±» (æ”¿ç­–å†…å®¹åˆ†æ)",
        "B": "B - æŠ€æœ¯ç±» (æŠ€æœ¯æ€è€ƒåˆ†æ)",
        "C": "C - äº‹ä»¶ç±» (äº‹ä»¶æ·±å±‚åˆ†æ)"
    }
    option_id_choice = st.radio(
        "è¯·é€‰æ‹©ç®€æŠ¥ç±»å‹ (å¯¹åº” optionId):",
        options=list(option_map.keys()),
        format_func=lambda x: option_map[x],
        key="option_id_key",
        horizontal=True
    )

    submitted = st.form_submit_button("å¼€å§‹ç”Ÿæˆç®€æŠ¥")

# --- ç»“æœå±•ç¤º ã€æ ¸å¿ƒä¿®æ”¹åŒºåŸŸã€‘ ---
if submitted and workflow_input:

    final_state = run_langgraph(workflow_input, option_id_choice)

    if final_state:

        # æå–å…³é”®ç»“æœ
        export_path = final_state.get('export_path', 'KEY_MISSING_IN_FINAL_STATE')
        briefing_draft = final_state.get('briefing_draft')
        final_briefing = final_state.get('final_briefing')

        # å°è¯•ä½¿ç”¨çš„æ–‡ä»¶è·¯å¾„
        final_file_path = None

        st.subheader("ğŸ‰ æœ€ç»ˆç»“æœ")

        if export_path != 'KEY_MISSING_IN_FINAL_STATE' and "å¯¼å‡ºå¤±è´¥" not in export_path and export_path:
            # æƒ…å†µ 1: LangGraph æˆåŠŸè¿”å›äº†è·¯å¾„ (æœ€ä½³æƒ…å†µ)
            final_file_path = export_path
            st.success(f"æ–‡ä»¶å·²ä¿å­˜è‡³ï¼š`{final_file_path}`")
        else:
            # æƒ…å†µ 2: è·¯å¾„ä¸¢å¤±æˆ–è¿”å›é”™è¯¯ï¼Œå°è¯•ä»æœ¬åœ°ç›®å½•ä¸­æ¢å¤
            st.warning(f"DOCX æ–‡ä»¶å¯¼å‡ºè·¯å¾„è¿”å›å¼‚å¸¸ã€‚è¯Šæ–­å€¼: {export_path}ã€‚æ­£åœ¨å°è¯•ä»æœ¬åœ°ç›®å½•æ¢å¤æ–‡ä»¶...")
            recovered_path = find_latest_briefing_file()

            if recovered_path and os.path.exists(recovered_path):
                final_file_path = recovered_path
                st.success(f"âœ… æˆåŠŸä»æœ¬åœ°ç›®å½•æ¢å¤æœ€æ–°çš„ç®€æŠ¥æ–‡ä»¶è·¯å¾„ï¼š`{final_file_path}`")
            else:
                st.error("âŒ æ— æ³•ä»æœ¬åœ°ç›®å½•ä¸­æ‰¾åˆ°å·²ç”Ÿæˆçš„ç®€æŠ¥æ–‡ä»¶ã€‚è¯·æ£€æŸ¥ `generated_briefings/` æ–‡ä»¶å¤¹ã€‚")

        # --- ä¸‹è½½æŒ‰é’®é€»è¾‘ ---
        if final_file_path and os.path.exists(final_file_path):
            try:
                # å¿…é¡»ä½¿ç”¨ 'rb' æ¨¡å¼æ‰“å¼€æ–‡ä»¶ï¼Œå¹¶è·å–æ–‡ä»¶å¯¹è±¡
                with open(final_file_path, "rb") as file:
                    st.download_button(
                        label="ğŸ“¥ ç‚¹å‡»ä¸‹è½½ DOCX ç®€æŠ¥",
                        # ç›´æ¥ä¼ é€’æ–‡ä»¶å¯¹è±¡ç»™ data å‚æ•°
                        data=file.read(),
                        file_name=os.path.basename(final_file_path),
                        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                    )
            except Exception as e:
                st.warning(f"æ— æ³•åˆ›å»ºä¸‹è½½é“¾æ¥ã€‚è¯·æ‰‹åŠ¨ä» `{final_file_path}` è·å–æ–‡ä»¶ã€‚é”™è¯¯: {e}")
        elif not final_file_path and export_path == 'KEY_MISSING_IN_FINAL_STATE':
            st.error("ç®€æŠ¥ç”Ÿæˆå¤±è´¥ï¼ŒLangGraph æœªè¿”å›è·¯å¾„ä¸”æ— æ³•åœ¨æœ¬åœ°ç›®å½•ä¸­æ¢å¤æ–‡ä»¶ã€‚è¯·è°ƒè¯• LangGraphã€‚")

        # è¯¦ç»†å†…å®¹é¢„è§ˆ
        with st.expander("é¢„è§ˆæœ€ç»ˆç®€æŠ¥å†…å®¹ (æ–‡æœ¬)", expanded=True):
            if final_briefing:
                st.code(final_briefing, language='markdown')
            else:
                st.write("æœ€ç»ˆç®€æŠ¥å†…å®¹ä¸ºç©ºã€‚")

        # è°ƒè¯•ä¿¡æ¯
        with st.expander("æŸ¥çœ‹æ‰€æœ‰çŠ¶æ€å˜é‡ (è°ƒè¯• - å®Œæ•´)", expanded=False):
            st.json(final_state)

        with st.expander("æŸ¥çœ‹ç¬¬ä¸€ç« åˆç¨¿ (è°ƒè¯•)", expanded=False):
            st.markdown(briefing_draft)


elif submitted and not workflow_input:
    st.warning("è¯·è¾“å…¥è¦åˆ†æçš„ä¸»é¢˜æˆ–äº‹ä»¶æ‰èƒ½å¼€å§‹ã€‚")